{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Antonio\\Anaconda3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import requests, bs4\n",
    "from bs4 import BeautifulSoup\n",
    "from fuzzywuzzy import fuzz \n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = pd.read_csv(current_path + \"\\\\Dataset\\\\precision_agriculture_patents_from_LENS.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84038, 30)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing missing values and duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = data_set.drop_duplicates(subset =\"Publication_Number\", keep = \"last\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#                                  0\n",
       "Jurisdiction                       0\n",
       "Kind                               0\n",
       "Publication_Number                 0\n",
       "Lens_ID                            0\n",
       "Publication_Date                   0\n",
       "Publication_Year                   0\n",
       "Application_Number                 0\n",
       "Application_Date                   0\n",
       "Priority_Numbers                   0\n",
       "Earliest_Priority_Date             0\n",
       "Title                              0\n",
       "Applicants                         7\n",
       "Inventors                        103\n",
       "Owners_(US)                    72268\n",
       "URL                                0\n",
       "Type                               0\n",
       "Has_Full_Text                      0\n",
       "Cited_by_Patent_Count              0\n",
       "Simple_Family_Size                 0\n",
       "Extended_Family_Size               0\n",
       "Sequence_Count                     0\n",
       "CPC_Classifications            18892\n",
       "IPCR_Classifications             634\n",
       "US_Classifications             49108\n",
       "NPL_Citation_Count                 0\n",
       "NPL_Resolved_Citation_Count        0\n",
       "NPL_Resolved_Lens_ID(s)        63027\n",
       "NPL_Resolved_External_Id(s)    63027\n",
       "NPL_Citations                  56952\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = data_set.dropna(subset=['IPCR_Classifications']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75243, 30)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing not necessary columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#', 'Jurisdiction', 'Kind', 'Publication_Number', 'Lens_ID',\n",
       "       'Publication_Date', 'Publication_Year', 'Application_Number',\n",
       "       'Application_Date', 'Priority_Numbers', 'Earliest_Priority_Date',\n",
       "       'Title', 'Applicants', 'Inventors', 'Owners_(US)', 'URL', 'Type',\n",
       "       'Has_Full_Text', 'Cited_by_Patent_Count', 'Simple_Family_Size',\n",
       "       'Extended_Family_Size', 'Sequence_Count', 'CPC_Classifications',\n",
       "       'IPCR_Classifications', 'US_Classifications', 'NPL_Citation_Count',\n",
       "       'NPL_Resolved_Citation_Count', 'NPL_Resolved_Lens_ID(s)',\n",
       "       'NPL_Resolved_External_Id(s)', 'NPL_Citations'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['#', 'Jurisdiction', 'Kind', 'Lens_ID',\n",
    "       'Publication_Date', 'Application_Number',\n",
    "       'Application_Date', 'Priority_Numbers', 'Earliest_Priority_Date',\n",
    "       'Inventors', 'Owners_(US)', 'URL', 'Type',\n",
    "       'Has_Full_Text', 'Cited_by_Patent_Count', 'Simple_Family_Size',\n",
    "       'Extended_Family_Size', 'Sequence_Count', 'CPC_Classifications',\n",
    "       'US_Classifications', 'NPL_Citation_Count',\n",
    "       'NPL_Resolved_Citation_Count', 'NPL_Resolved_Lens_ID(s)',\n",
    "       'NPL_Resolved_External_Id(s)', 'NPL_Citations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = data_set.drop(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75243, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct the names of the top 300 applicants e.g. \"Mosanto Technology LLC\" -> \"Monsanto Technology LLC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 29min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "first_300_applicants = list(data_set['Applicants'].value_counts().sort_values(ascending=False).index[:300])\n",
    "choices = data_set.Applicants.unique()\n",
    "for i in first_300_applicants:\n",
    "    a = process.extract(i, choices, limit=100, scorer=fuzz.token_sort_ratio)\n",
    "    for j in a:\n",
    "        if j[1]>75:\n",
    "            data_set.Applicants.replace(j[0], i, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating 2 columns containing the main class and the main subclass of each patent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assigne_class_subclass(Ipcr_class):\n",
    "    ipcr_values = Ipcr_class.split(';;')\n",
    "    class_values= []\n",
    "    subclass_values = []\n",
    "    for ipcr in ipcr_values:\n",
    "        class_values.append(ipcr[:3])\n",
    "        subclass_values.append(ipcr[:4])\n",
    "        \n",
    "    return max(class_values,key=class_values.count), max(subclass_values,key=subclass_values.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set['Main_Class'] = \"\"\n",
    "data_set['Main_Subclass'] = \"\"\n",
    "for i in range(len(data_set)):\n",
    "    classe, subclass = assigne_class_subclass(data_set.IPCR_Classifications[i])\n",
    "    data_set.loc[i,\"Main_Class\"] = classe\n",
    "    data_set.loc[i,\"Main_Subclass\"] = subclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting data with a crawler "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### We suggest to test the crawler with the given indexes because the execution on the whole dataset it requires days and jump to the slot:  \n",
    "[ data_crawler = pd.read_csv(current_path+\"\\\\Dataset\\\\crawler_result.csv\") ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_index = 0\n",
    "final_index = 5\n",
    "df = data_set[initial_index:final_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_list = df.Publication_Number\n",
    "URL_list = []\n",
    "for id_num in ID_list:\n",
    "    ending_url = id_num\n",
    "    ending_url = ending_url.replace(\" \",\"\")\n",
    "    ending_url = ending_url.replace(\"/\",\"\")\n",
    "    URL_list.append(\"https://patents.google.com/patent/\" + ending_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getting_data_from_patent(id_num, link):\n",
    "    citation_id_string = \"\"\n",
    "    citation_date_string = \"\"\n",
    "    cited_id_string = \"\"\n",
    "    cited_date_string = \"\"\n",
    "\n",
    "    try:\n",
    "        response = requests.get(link)\n",
    "    except:\n",
    "        print(\"Error URL with: \" + link)\n",
    "        return -1\n",
    "    \n",
    "    if(response.status_code == 404):\n",
    "        print(\"Status 404: \" + link)\n",
    "        return 404\n",
    "    \n",
    "    try:\n",
    "        patentSoup = bs4.BeautifulSoup(response.text)\n",
    "        citations = patentSoup.find_all(\"tr\", itemprop=\"backwardReferencesOrig\")\n",
    "        cited = patentSoup.find_all(\"tr\", itemprop=\"forwardReferencesOrig\")\n",
    "    except:\n",
    "        print(\"Eccezione citations: \" + link)\n",
    "        return 300\n",
    "    try:        \n",
    "        abstract = patentSoup.find(name=\"abstract\").text\n",
    "    except:\n",
    "        abstract = \"\"\n",
    "        \n",
    "    try:\n",
    "        claims_section = patentSoup.find_all(\"section\", itemprop=\"claims\")\n",
    "    except:\n",
    "        print(\"Eccezione claim Section: \" + link)\n",
    "        return 300\n",
    "    \n",
    "    try:\n",
    "        claims_occ = claims_section[0].find(\"span\", itemprop=\"count\").text\n",
    "    except:\n",
    "        try:\n",
    "            x = claims_section[0].find(\"div\", itemprop=\"content\")\n",
    "            claims_occ = len(x.find_all(\"claim\"))\n",
    "        except:\n",
    "            claims_occ = 0\n",
    "        \n",
    "    for elem in citations:\n",
    "        pub_num_citation = elem.find(itemprop=\"publicationNumber\").text\n",
    "        citation_id_string = citation_id_string + pub_num_citation + \";;\"\n",
    "        \n",
    "        pub_date_citation = elem.find(itemprop=\"priorityDate\").text\n",
    "        citation_date_string = citation_date_string + pub_date_citation + \";;\"\n",
    "    \n",
    "    for elem in cited:\n",
    "        pub_num_cited = elem.find(itemprop=\"publicationNumber\").text\n",
    "        cited_id_string = cited_id_string + pub_num_cited + \";;\"\n",
    "        \n",
    "        pub_date_cited = elem.find(itemprop=\"priorityDate\").text\n",
    "        cited_date_string = cited_date_string + pub_date_cited + \";;\"\n",
    "\n",
    "    abstract = abstract[1:]\n",
    "    citation_id_string = citation_id_string[:-2]\n",
    "    citation_date_string = citation_date_string[:-2]\n",
    "    cited_id_string = cited_id_string[:-2]\n",
    "    cited_date_string = cited_date_string[:-2]\n",
    "    \n",
    "    return id_num, abstract, claims_occ, len(citations), citation_id_string, citation_date_string, len(cited), cited_id_string, cited_date_string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = ['Publication_Number', 'Abstract', 'Claims_count', 'Citation_count', 'Citation_ids','Citation_dates', 'Cited_count', 'Cited_ids' ,'Cited_dates']\n",
    "data_crawler =  pd.DataFrame(columns = attributes)\n",
    "patent_num = 1 \n",
    "total_patents = (len(ID_list))\n",
    "not_found = 0\n",
    "excep = 0\n",
    "\n",
    "for id_num in ID_list:\n",
    "    row = tuple()\n",
    "    print (\"Patent \" + str(patent_num) + \" of \" + str(total_patents))\n",
    "    ending_url = id_num\n",
    "    ending_url = ending_url.replace(\" \",\"\")\n",
    "    ending_url = ending_url.replace(\"/\",\"\")\n",
    "    url = \"https://patents.google.com/patent/\" + ending_url\n",
    "\n",
    "    row = getting_data_from_patent(id_num, url)\n",
    "    if row == -1:\n",
    "        break\n",
    "    if row == 404:\n",
    "        not_found = not_found + 1\n",
    "    elif row == 300:\n",
    "        excep = excep + 1\n",
    "    else: \n",
    "        data_crawler = data_crawler.append(pd.Series(row, index=data_crawler.columns ), ignore_index=True)\n",
    "        \n",
    "    patent_num = patent_num + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_crawler = pd.read_csv(current_path+\"\\\\Dataset\\\\crawler_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(data_set, data_crawler, on='Publication_Number', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=Trueue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72224, 15)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = current_path +\"\\\\Dataset\\\\precision_agriculture_patents.csv\"\n",
    "df.to_csv(output_path, index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
